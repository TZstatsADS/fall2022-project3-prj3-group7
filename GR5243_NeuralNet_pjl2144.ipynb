{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "noisy = '/Users/peter/Downloads/train_data/noisy_labels.csv'\n",
    "clean = '/Users/peter/Downloads/train_data/clean_labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_labels = pd.read_csv(clean,header = None).rename(columns={0:'label'})\n",
    "noisy_labels = pd.read_csv(noisy,header=None).rename(columns={0:'label'}) #fixed zero index issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "direx = '/Users/peter/Downloads/train_data/'\n",
    "list_of_labels = list(noisy_labels['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = 50000\n",
    "n_noisy = 40000\n",
    "n_clean_noisy = n_img - n_noisy\n",
    "imgs = np.empty((n_img,32,32,3))\n",
    "for i in range(n_img):\n",
    "    img_fn = f'/Users/peter/Downloads/train_data/images/{i+1:05d}.png'\n",
    "    imgs[i,:,:,:]=cv2.cvtColor(cv2.imread(img_fn),cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [DO NOT MODIFY THIS CELL]\n",
    "# RGB histogram dataset construction\n",
    "no_bins = 6\n",
    "bins = np.linspace(0,255,no_bins) # the range of the rgb histogram\n",
    "target_vec = np.empty(n_img)\n",
    "feature_mtx = np.empty((n_img,3*(len(bins)-1)))\n",
    "i = 0\n",
    "for i in range(n_img):\n",
    "    # The target vector consists of noisy labels\n",
    "    target_vec[i] = list_of_labels[i]\n",
    "    \n",
    "    # Use the numbers of pixels in each bin for all three channels as the features\n",
    "    feature1 = np.histogram(imgs[i][:,:,0],bins=bins)[0] \n",
    "    feature2 = np.histogram(imgs[i][:,:,1],bins=bins)[0]\n",
    "    feature3 = np.histogram(imgs[i][:,:,2],bins=bins)[0]\n",
    "    \n",
    "    # Concatenate three features\n",
    "    feature_mtx[i,] = np.concatenate((feature1, feature2, feature3), axis=None)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tf.convert_to_tensor(target_vec, dtype=tf.int32)\n",
    "imgs1 = tf.convert_to_tensor(imgs, dtype=tf.int32)\n",
    "\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(imgs1)\n",
    "\n",
    "#tfg = tf.data.Dataset.from_tensor_slices((imgs1,target)).batch(64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model I FIT\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Rescaling(1./255))\n",
    "model.add(tf.keras.layers.Conv2D(128, (3, 3), input_shape=(32,32,3)))\n",
    "model.add(tf.keras.layers.Activation('relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3)))\n",
    "model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128,activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  \n",
    "              metrics=['accuracy']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 99s 63ms/step - loss: 2.2857 - accuracy: 0.1366\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 100s 64ms/step - loss: 2.2496 - accuracy: 0.1782\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 2.2337 - accuracy: 0.1944\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 118s 75ms/step - loss: 2.2207 - accuracy: 0.2063\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 123s 79ms/step - loss: 2.2049 - accuracy: 0.2205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fba55b32128>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(imgs1,target, epochs = 5) #50,000/32 = 1563 examples per training epoch $fit on dirty labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model.fit(tfg, epochs = 10) #50,000/32 = 1563 examples per training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "MobileNet = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(32,32,3), include_top=False, weights='imagenet')\n",
    "\n",
    "MobileNet.trainable=False\n",
    "model_transfer = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Rescaling(1./255),\n",
    "                            MobileNet, \n",
    "\n",
    "                            tf.keras.layers.Flatten(),\n",
    "                            tf.keras.layers.Dense(128),\n",
    "                            tf.keras.layers.Dense(10, activation = 'relu')                            \n",
    "                            ])\n",
    "\n",
    "model_transfer.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  \n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 43s 26ms/step - loss: 2.2832 - accuracy: 0.1462\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 41s 26ms/step - loss: 2.2664 - accuracy: 0.1622\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 50s 32ms/step - loss: 2.2600 - accuracy: 0.1669\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 48s 31ms/step - loss: 2.2567 - accuracy: 0.1698\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 2.2547 - accuracy: 0.1717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fba54b88ac8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transfer.fit(tfg, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
